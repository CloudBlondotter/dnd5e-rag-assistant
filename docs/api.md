Bas√°ndome en los resultados de b√∫squeda sobre documentaci√≥n de APIs[1][2][3][4] y tu proyecto RAG de D&D, aqu√≠ est√° el contenido para `docs/api.md`:

```markdown
# üîß Documentaci√≥n T√©cnica - D&D 5E RAG Assistant

Esta documentaci√≥n est√° dirigida a desarrolladores que quieren entender, modificar o contribuir al sistema.

## üìã Arquitectura del Sistema

### Componentes Principales

```
src/
‚îú‚îÄ‚îÄ config.py           # Configuraciones centralizadas
‚îú‚îÄ‚îÄ vector_pipeline.py  # Pipeline de procesamiento de documentos
‚îú‚îÄ‚îÄ rag_interface.py    # Interfaz de usuario y motor de consultas
‚îî‚îÄ‚îÄ prompts.py         # Templates de prompts (si existe)
```

### Flujo de Datos

```
Documentos MD ‚Üí vector_pipeline ‚Üí ChromaDB ‚Üí rag_interface ‚Üí Usuario
     ‚Üì              ‚Üì              ‚Üì           ‚Üì
  Parsing      Embeddings    Almacenamiento  Consultas
```

## ‚öôÔ∏è M√≥dulo: config.py

### Variables de Configuraci√≥n

| Variable | Tipo | Descripci√≥n | Por Defecto |
|----------|------|-------------|-------------|
| `PROJECT_ROOT` | Path | Directorio ra√≠z del proyecto | Auto-detectado |
| `DATA_DIR` | Path | Directorio de archivos Markdown | `data/markdown` |
| `DB_DIR` | Path | Directorio de base de datos vectorial | `storage/db_dungeons` |
| `EMBEDDINGS_MODEL` | str | Modelo de embeddings de Ollama | `bge-m3:latest` |
| `LLM_MODEL` | str | Modelo de lenguaje de Ollama | `gemma2:9b` |
| `CHUNK_SIZE` | int | Tama√±o m√°ximo de chunks | 800 |
| `CHUNK_OVERLAP` | int | Solapamiento entre chunks | 100 |
| `RETRIEVAL_K` | int | Documentos a recuperar por consulta | 5 |

### Ejemplo de Uso

```
from config import DATA_DIR, EMBEDDINGS_MODEL

# Verificar directorio de datos
if DATA_DIR.exists():
    print(f"Datos encontrados en: {DATA_DIR}")

# Usar configuraci√≥n en tu c√≥digo
model = OllamaEmbeddings(model=EMBEDDINGS_MODEL)
```

## üìÑ M√≥dulo: vector_pipeline.py

### Funciones Principales

#### `init_or_update()`

**Descripci√≥n**: Inicializa o actualiza la base de datos vectorial.

**Par√°metros**: Ninguno

**Retorna**: `Chroma` - Instancia de la base de datos vectorial

**Ejemplo**:
```
from vector_pipeline import init_or_update

vector_store = init_or_update()
if vector_store:
    print("Base de datos lista")
```

#### `get_retriever(k: int = 4)`

**Descripci√≥n**: Obtiene un retriever configurado (patr√≥n singleton).

**Par√°metros**:
- `k` (int): N√∫mero de documentos a recuperar por consulta

**Retorna**: Retriever de LangChain configurado

**Ejemplo**:
```
from vector_pipeline import get_retriever

retriever = get_retriever(k=5)
docs = retriever.invoke("¬øQu√© es un Elfo?")
```

#### `split_markdown_document(md_text: str, doc_name: str)`

**Descripci√≥n**: Divide un documento Markdown en chunks procesables.

**Par√°metros**:
- `md_text` (str): Contenido completo del archivo Markdown
- `doc_name` (str): Nombre del documento para metadatos

**Retorna**: `List[Document]` - Lista de documentos procesados

**Proceso**:
1. Divide por p√°ginas l√≥gicas (separadas por `---`)
2. Dentro de cada p√°gina, divide por headers
3. Si los chunks son muy grandes, divide por tama√±o
4. A√±ade metadatos completos

**Ejemplo**:
```
from vector_pipeline import split_markdown_document

with open("manual.md", "r") as f:
    content = f.read()

chunks = split_markdown_document(content, "Manual del Jugador")
print(f"Generados {len(chunks)} chunks")
```

#### `get_database_stats()`

**Descripci√≥n**: Obtiene estad√≠sticas de la base de datos vectorial.

**Retorna**: `Dict[str, Any]` - Estad√≠sticas de la base de datos

**Estructura de Respuesta**:
```
{
    "status": "active",           # active | no_database | error
    "document_count": 1247,       # N√∫mero de documentos indexados
    "processed_files": 3,         # Archivos procesados
    "last_update": "2025-01-15 10:30:45"  # √öltima actualizaci√≥n
}
```

### Utilidades Internas

#### `normalize_filename(path: str | bytes)`
- Normaliza nombres de archivo para usar como clave √∫nica

#### `calculate_file_hash(file_path: str)`
- Calcula hash MD5 para detectar cambios en archivos

#### `build_context_and_sources(docs)`
- Construye contexto y extrae fuentes de documentos recuperados

## ü§ñ M√≥dulo: rag_interface.py

### Cadenas de Procesamiento

#### `initialize_chains(model, retriever)`

**Descripci√≥n**: Inicializa las cadenas de procesamiento con el modelo y retriever dados.

**Par√°metros**:
- `model`: Instancia del modelo LLM
- `retriever`: Retriever configurado

**Retorna**: Diccionario con cadenas configuradas

**Estructura de Retorno**:
```
{
    "answer_chain": ChatPromptTemplate | LLM | StrOutputParser,
    "decomposition_chain": ChatPromptTemplate | LLM | StrOutputParser,
    "synthesis_chain": ChatPromptTemplate | LLM | StrOutputParser,
    "retriever": retriever
}
```

### Procesamiento de Consultas

#### `process_normal_query(chains, prompt)`

**Descripci√≥n**: Procesa una consulta normal sin descomposici√≥n.

**Par√°metros**:
- `chains` (dict): Cadenas de procesamiento inicializadas
- `prompt` (str): Consulta del usuario

**Retorna**: Tupla `(answer, sources)`

#### `process_decomposition_query(chains, prompt)`

**Descripci√≥n**: Procesa una consulta con descomposici√≥n secuencial.

**Par√°metros**:
- `chains` (dict): Cadenas de procesamiento inicializadas  
- `prompt` (str): Consulta del usuario

**Retorna**: Tupla `(final_answer, final_sources)`

**Proceso**:
1. Genera sub-preguntas usando `decomposition_chain`
2. Responde cada sub-pregunta individualmente
3. Sintetiza respuesta final usando `synthesis_chain`

### Templates de Prompts

#### ANSWER_PROMPT
- **Prop√≥sito**: Respuestas normales y s√≠ntesis
- **Variables**: `{context}`, `{question}`

#### DECOMPOSITION_PROMPT  
- **Prop√≥sito**: Descomposici√≥n de consultas complejas
- **Variables**: `{question}`
- **Salida esperada**: Lista numerada de sub-preguntas

#### SYNTHESIS_PROMPT
- **Prop√≥sito**: S√≠ntesis final de sub-respuestas
- **Variables**: `{original_question}`, `{subquestions}`, `{context}`

## üõ†Ô∏è Scripts de Utilidad

### setup_db.py

**Comandos disponibles**:

```
python scripts/setup_db.py init [--force]    # Inicializar BD
python scripts/setup_db.py stats             # Ver estad√≠sticas
python scripts/setup_db.py reset             # Resetear BD
python scripts/setup_db.py check             # Verificar prerrequisitos
python scripts/setup_db.py add file1.md ...  # A√±adir archivos
```

### run_app.py

**Funci√≥n**: Lanza la aplicaci√≥n Streamlit

```
python scripts/run_app.py
```

## üîß Personalizaci√≥n Avanzada

### Modificar Prompts

Los prompts est√°n definidos en `rag_interface.py`. Para modificarlos:

```
# Ejemplo: Modificar prompt de respuesta
CUSTOM_ANSWER_PROMPT = ChatPromptTemplate.from_template("""
Eres un experto Dungeon Master especializado en D&D 5E.

CONTEXTO: {context}
PREGUNTA: {question}

Responde con:
1. Respuesta directa
2. Explicaci√≥n detallada  
3. Ejemplos pr√°cticos
4. Referencias espec√≠ficas

RESPUESTA:
""")
```

### A√±adir Nuevos Modelos

Para soportar otros modelos LLM:

```
# En config.py
LLM_PROVIDERS = {
    "ollama": OllamaLLM,
    "openai": ChatOpenAI,
    "anthropic": ChatAnthropic
}

# Uso din√°mico
provider = LLM_PROVIDERS[config.LLM_PROVIDER]
model = provider(model=config.LLM_MODEL)
```

### M√©tricas Personalizadas

Para a√±adir m√©tricas de rendimiento:

```
import time
from functools import wraps

def measure_time(func):
    @wraps(func)
    def wrapper(*args, **kwargs):
        start = time.time()
        result = func(*args, **kwargs)
        duration = time.time() - start
        print(f"{func.__name__} ejecutado en {duration:.2f}s")
        return result
    return wrapper

@measure_time
def enhanced_retrieval(query):
    # Tu l√≥gica de retrieval
    pass
```


## üîÑ Contribuci√≥n

### Estructura de Commits

```
feat: a√±adir soporte para nuevos formatos de documento
fix: corregir error en divisi√≥n de chunks grandes
docs: actualizar documentaci√≥n de API
refactor: optimizar consultas a base de datos
```

### Pull Requests

1. Crear rama feature: `git checkout -b feature/nueva-funcionalidad`
2. Implementar cambios con tests
3. Actualizar documentaci√≥n
4. Crear PR con descripci√≥n detallada

### Est√°ndares de C√≥digo

- **Formato**: Black (`black src/`)
- **Linting**: Flake8 (`flake8 src/`) 
- **Type hints**: mypy (`mypy src/`)
- **Docstrings**: Formato Google

## üìö Recursos Adicionales

### Dependencies

Ver `requirements.txt` para lista completa:

```
streamlit>=1.20.0
langchain>=0.1.0
langchain-community>=0.0.20
langchain-ollama>=0.1.0
chromadb>=0.4.0
pandas>=1.5.0
tqdm>=4.64.0
```

### Configuraci√≥n IDE

**VS Code** (`.vscode/settings.json`):
```
{
    "python.defaultInterpreterPath": "./venv/bin/python",
    "python.linting.enabled": true,
    "python.linting.flake8Enabled": true,
    "python.formatting.provider": "black"
}
```

---

**üîß Esta documentaci√≥n est√° dise√±ada para desarrolladores que quieren contribuir o modificar el sistema RAG de D&D 5E.**
```
